{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5584254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn  # nn contains all of PyTorch's building blocks for neural networks\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(f\"GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Check PyTorch version\n",
    "print(\"Torch Version\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aab3868",
   "metadata": {},
   "source": [
    "### Creating a simple dataset using the linear regression formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1e5279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create *known* parameters\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "# Create\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "\n",
    "x = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weight * x + bias\n",
    "\n",
    "# x[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bd985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(x), len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb43e029",
   "metadata": {},
   "source": [
    "### Splitting data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeede05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train/test split\n",
    "train_split = int(0.8 * len(x))\n",
    "x_train, y_train = x[:train_split], y[:train_split]\n",
    "x_test, y_test = x[train_split:], y[train_split:]\n",
    "len(x_train), len(y_train), len(x_test), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df7e014",
   "metadata": {},
   "source": [
    "### Exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde52a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(\n",
    "    train_data=x_train,\n",
    "    train_labels=y_train,\n",
    "    test_data=x_test,\n",
    "    test_labels=y_test,\n",
    "    predictions=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots training data, test data and compares predictions.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 7))\n",
    "\n",
    "    # Plot training data in blue\n",
    "    plt.scatter(train_data, train_labels, s=4, c=\"b\", label=\"Training data\")\n",
    "\n",
    "    # Plot test data in green\n",
    "    plt.scatter(test_data, test_labels, s=4, c=\"g\", label=\"Testing data\")\n",
    "\n",
    "    # Are there predictions?\n",
    "    if predictions is not None:\n",
    "        # Plot the predictions if they exists\n",
    "        plt.scatter(test_data, predictions, s=4, c=\"r\", label=\"Predictions\")\n",
    "\n",
    "    # Show the legend\n",
    "    plt.legend(prop={\"size\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973acfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5905ab",
   "metadata": {},
   "source": [
    "### Building first PyTorch model!\n",
    " * start with randon values (weight & bias)\n",
    " * look at the training data and adjust the random values to better represent (or get closer to) the ideal values (the weight and bias values we used to create the data)\n",
    "\n",
    "\n",
    "How does it do so?\n",
    "Through two main algorithms:\n",
    "1. Gradient descent\n",
    "2. Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18420f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Create a linerar regression model class\n",
    "class LinearRegressionModel(\n",
    "    nn.Module  # <- nn.Module contains all the building blocks for neural network\n",
    "):  # <- almost everything in PyTorch inherits from nn.Module\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initalize model parameters\n",
    "        self.weight = nn.Parameter(\n",
    "            torch.randn(\n",
    "                1,  # <- start with a random weight and try to adjust it to the ideal weight\n",
    "                requires_grad=True,  # <- can this parameter be updated via gradient descent?\n",
    "                dtype=torch.float32,  # PyTorch loves the datatype torch.float32\n",
    "            )\n",
    "        )  # <- PyTorch loves the datatype torch.float32\n",
    "\n",
    "        self.bias = nn.Parameter(\n",
    "            torch.randn(\n",
    "                1,  # <- start with a random bias and try to adjust it to the ideal bias\n",
    "                requires_grad=True,  # <- can this parameter be updated via gradient descent?\n",
    "                dtype=torch.float32,  # PyTorch loves the datatype torch.float32\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Forward method to define the computation in the model, all subclasses of nn.Module need to overwrite forward method.\n",
    "    # This defines the forward computation of the model\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:  # <- \"x\" is the input data\n",
    "        return self.weight * x + self.bias  # this is the linear regression formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ff5d5d",
   "metadata": {},
   "source": [
    "### PyTorch model building essentials\n",
    "\n",
    "1. **torch.nn** - contains all of the buildings for computational graphs (a neural network can be considered a computational graph)\n",
    "\n",
    "2. **torch.nn.Parameter** - what parameters should our model try and learn, often a PyTorch layer from torch.nn will set these for us.\n",
    "\n",
    "3. **torch.nn.Module** - The base class for all neural network modules, if you subclass it, you should overwrite forward()\n",
    "\n",
    "4. **torch.optim** - this where the optimizers in PyTorch live, they will help with gradient descent\n",
    "\n",
    "5. **def forward()** - All nn.Module subclasses require you to overwrite forward(), this method defines what happens in the forward computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bc2346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create an instance of the model (the model is a subclass of nn.Module)\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "# Checkout out the parameters\n",
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05e9460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List names parameters\n",
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b991c776",
   "metadata": {},
   "source": [
    "### Making predictions using `torch.inference_mode()`\n",
    "\n",
    "To check our model's predictive power, let's see how well it predicts `y_test` based on `x_test`.\n",
    "\n",
    "When we pass data through our mode, it's going it through the forward() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92447f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a51e846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with model\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_0(x_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64655206",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(predictions=y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20f1fdf",
   "metadata": {},
   "source": [
    "### 3. Train model\n",
    "\n",
    "The whole idea of training is for a model to move from some *unknown* parameterrs (these may be random) to some *known* parameters.\n",
    "\n",
    "or in other words from a poor representation of the data to a better representation of the data.\n",
    "\n",
    "One ways to measure how poor or how wrong your models predictions are is to use a loss function.\n",
    "\n",
    "* Note: Loss function may also be called cost function or criterion in different areas. For our case, we're going to refer to it as a loss function.\n",
    "\n",
    "Things we need to train:\n",
    "\n",
    "* **Loss function:** A function to measure how wrong your model's predictions are to the ideal outputs, lower it better.\n",
    "\n",
    "* **Optimizer:** Takes into account the loss of a model and adjusts the model's parameters (e.g. weight & bias)\n",
    "\n",
    "And specifically for PyTorch, we need:\n",
    "* A training loop\n",
    "* A testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b8ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d402f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7821585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# Setup an optiomizer (stochastic gradient descent)\n",
    "optimizer = torch.optim.SGD(\n",
    "    params=model_0.parameters(), lr=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69467ba6",
   "metadata": {},
   "source": [
    "### Building a training loop (and a testing toop) in PyTorch\n",
    "\n",
    "A coupple of things we need in a training loop:\n",
    "0. Loop through the data and do...\n",
    "1. forward pass (this involves data moving through our model's `forward()` functions) - also called forward propagation\n",
    "2. Calculate the loss (compare forward pass predictions to ground truth labels)\n",
    "3. Optimizer zero grad\n",
    "4. Loss backward - move backwards through the network to calculate the gradients of each of the parameters of our model with respest to the loss (**backpropagation**)\n",
    "5. Optimizer step - use the optimizer to adjust our model's parameters to try and improve the loss (**gradient descent**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f37e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An epoch is one loop through the data...(this is a hyperparameter because we've set it ourselves)\n",
    "epochs = 170\n",
    "\n",
    "# Track different values\n",
    "epoch_count = []\n",
    "train_loss = []\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "### Training\n",
    "# 0. Loop through the data\n",
    "for epoch in range(epochs):\n",
    "    # Set the model to training mode\n",
    "    model_0.train()  # train mode in PyTorch sets all parameters that require gradients to require gradients\n",
    "\n",
    "    # 1. Forward pass\n",
    "    y_preds = model_0(x_train)\n",
    "\n",
    "    # 2. Calculate the loss\n",
    "    loss = loss_fn(y_preds, y_train)\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Perform backpropagation on the loss with respect to the parameters of the model\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Step the optimizer (perform gradient descent)\n",
    "    optimizer.step()  # by default how the optimizer changes will accumulate through the loop so... we have to zero them above in step 3 for the next iteration of the loop\n",
    "\n",
    "    # Testing works with test data, training works with training data\n",
    "    model_0.eval()  # turns off different settings in the model not needed for evaluation/testing (dropout/batch norm layers).\n",
    "\n",
    "    # Make predictions after training\n",
    "    with torch.inference_mode():  # turns off gradient tracking & a couple of more things behing thr scenes that are not needed for evaluation/testing\n",
    "        # 1. Do the forward pass\n",
    "        test_pred = model_0(x_test)\n",
    "\n",
    "        # 2. Calculate the loss\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "    # Print out what's happening\n",
    "    if epoch % 10 == 0:\n",
    "        epoch_count.append(epoch)\n",
    "        train_loss_values.append(loss)\n",
    "        test_loss_values.append(test_loss)\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss} | Test loss: {test_loss}\")\n",
    " \n",
    "    # print(model_0.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ec756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss curves\n",
    "plt.plot(epoch_count, np.array(torch.tensor(train_loss_values).numpy()), label=\"Train loss\")\n",
    "plt.plot(epoch_count, test_loss_values, label=\"Test loss\")\n",
    "plt.title('Training and test loss curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb0e11c",
   "metadata": {},
   "source": [
    "### Saving a model in PyTorch\n",
    "\n",
    "There are three main methods you should know about for saving and loading models in PyTorch.\n",
    "\n",
    "1. `torch.save()` - allows you to save a PyTorch object in Python's pickle format.\n",
    "2. `torch.load()` - allows you to load a saved PyTorch object.\n",
    "3. `torch.nn.Module.load_state_dict()` -  this allows to load a model's saved state dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5aa286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving our PyTorch model\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Create models directory\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path\n",
    "MODEL_NAME = \"01_pytorch_workflow_model_0.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model state_dict\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model_0.state_dict(), f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9e940e",
   "metadata": {},
   "source": [
    "### Loading a PyTorch model\n",
    "Since we save our model's state_dict() rather than the entire mode, we'll create a new instance of our model class and load the saved state_dict() into that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb561ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ded7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load in a saved state_dict we have to instantiate a new instance of our model class\n",
    "loaded_model_0 = LinearRegressionModel()\n",
    "\n",
    "# Load the saved state_dict of model_0 (this will update the new instance with updated parameters)\n",
    "\n",
    "loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e69e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdb89c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions with our loaded model\n",
    "loaded_model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    loaded_model_preds = loaded_model_0(x_test)\n",
    "    \n",
    "loaded_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d211bd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_0(x_test)\n",
    "    \n",
    "# Compare loaded model preds with original model preds\n",
    "y_preds == loaded_model_preds\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
