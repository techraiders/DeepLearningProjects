{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78644a92",
   "metadata": {},
   "source": [
    "#### Computer vision libraries in PyTorch\n",
    "* `torchvision` - base domanin library for PyTorch\n",
    "* `torchvision.datasets` - get datasets and data loading functions for computer vision\n",
    "* `torchvision.models` - get pretrained computer vision models that you can leverage for your own problems\n",
    "* `torchvision.transforms` - functions for manipulating your vision data (images) to be suitable for use with an ML model\n",
    "* `torch.utils.data.Dataset` - Base dataset class for PyTorch.\n",
    "* `torch.utils.data.DataLoader` - Creates a Python iterable over a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca9d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Import torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check versions\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fac0a20",
   "metadata": {},
   "source": [
    "### 1. Getting a dataset\n",
    "\n",
    "The dataset we'll be using is FashionMNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e0bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training data\n",
    "from torchvision import datasets\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\", # where to download data to?\n",
    "    train=True, # do we want the training dataset?\n",
    "    download=True, # do we want to download yes/no\n",
    "    transform=torchvision.transforms.ToTensor(), # how do we want to transform the data\n",
    "    target_transform=None # how do we want to transform the labels/targets?\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\", # where to download data to?\n",
    "    train=False, # do we want the training dataset?\n",
    "    download=True, # do we want to download yes/no\n",
    "    transform=ToTensor(), # how do we want to transform the data\n",
    "    target_transform=None # how do we want to transform the labels/targets?\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387d839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0ad4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the first training example\n",
    "image, label = train_data[0]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa950484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072ba4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = train_data.class_to_idx\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644dfe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of our image\n",
    "print(f\"Image shape: {image.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Image label: {class_names[label]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0510c0b",
   "metadata": {},
   "source": [
    "### 1.2 Visualizing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e30adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image, label = train_data[0]\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "plt.imshow(image.squeeze())\n",
    "plt.title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ccc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb5bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot more images\n",
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 4, 4\n",
    "for i in range(1, rows * cols + 1):\n",
    "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    img, label = train_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f638b723",
   "metadata": {},
   "source": [
    "### 2. Prepare DataLoader\n",
    "Right now, our data is in the form of PyTorch datasets\n",
    "DataLoader turns our dataset into a Python iterable.\n",
    "More specifically, we want to turn our data into batches (or mini-batches).\n",
    "\n",
    "Why would we do this?\n",
    "1. It is computationally more efficient, as in your computing hardware may not be able to look (store in memory) at 60000 images in one hit. So we break it down to 32 images at a time (batch size of 32).\n",
    "\n",
    "2. It gives our neural network more chances to update its gradients per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebb7746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c68ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check out what we've created\n",
    "# print(f\"DataLoader: {train_dataloader, test_dataloader}\")\n",
    "print(f\"Length of train_dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}...\")\n",
    "print(f\"Length of test_dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df77e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out what's inside the training dataloader\n",
    "train_features_batch, train__labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train__labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5782b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a sample\n",
    "torch.manual_seed(42)\n",
    "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "img, label = train_features_batch[random_idx], train__labels_batch[random_idx]\n",
    "plt.imshow(img.squeeze(), cmap='gray')\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)\n",
    "print(f\"Image size: {img.shape}\")\n",
    "print(f\"Label: {label}, label size: {label.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20864301",
   "metadata": {},
   "source": [
    "### 3. Model 0: Build a baseline model\n",
    "When starting to build a series of machine learning modelling experiments, it's best practice to start with a baseline.\n",
    "\n",
    "A baseline model is a simple model you will try and improve upon with subsequent models/experiments.\n",
    "\n",
    "In other words: start simply and add complexity when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4b755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creaete a flatten layer\n",
    "flatten_model = nn.Flatten()\n",
    "\n",
    "# Get a single sample\n",
    "x = train_features_batch[0]\n",
    "\n",
    "# Flatten the sample\n",
    "output = flatten_model(x) # perform forward pass\n",
    "print(f\"Shape before flattening: {x.shape} -> [color channels, height, width]\")\n",
    "print(f\"Shape after flattening: {output.shape} -> [color channels, height*width]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240b2de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class FashionMNISTModelV0(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49006f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_0 = FashionMNISTModelV0(\n",
    "    input_shape=784, hidden_units=10, output_shape=len(class_names)  # this is 28 * 28\n",
    ").to('cpu')\n",
    "\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a6389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_x = torch.rand([1,1,28,28])\n",
    "model_0(dummy_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee47dd9f",
   "metadata": {},
   "source": [
    "### 3.1 Setup loss optimizer and evaluation metrics\n",
    "* Loss function - since we're working with multi-class, our loss function will be `nn.CrossEntropyLoss()`\n",
    "* Optimizer - our optimizer `torch.optim.SGD()` (stochastic gradient descent)\n",
    "* Evaluation metric - since we're working on a classification problem, let's use accuracy as our evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fe9930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# Download helder functions from Learn PyTorch repo\n",
    "if Path(\"helper_functions.py\").is_file():\n",
    "    print(\"helper_functions.py already exists, skipping download...\")\n",
    "else:\n",
    "    print(\"Downloading helper_functions.py\")\n",
    "    request = requests.get(\n",
    "        \"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/refs/heads/main/helper_functions.py\"\n",
    "    )\n",
    "    with open(\"helper_functions.py\", \"wb\") as f:\n",
    "        f.write(request.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ef8845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import accuracy metric\n",
    "from helper_functions import accuracy_fn\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f845f7ab",
   "metadata": {},
   "source": [
    "#### 3.2 Creating a function to time out experiments\n",
    "\n",
    "Machine learning is very experimental.\n",
    "\n",
    "Two of the main things you'll often want to track are:\n",
    "1. Model's performance (loss and accuracy values etc.)\n",
    "2. How fast it runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2485d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    \"\"\"Prints difference between start and end time.\"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time: .3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82030ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timer()\n",
    "#some code...\n",
    "end_time = timer()\n",
    "print_train_time(start=start_time, end=end_time, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d0b3b9",
   "metadata": {},
   "source": [
    "#### 3.3 Creating a training loop and training a model on batches of data\n",
    "\n",
    "1. Loop through epochs.\n",
    "2. Loop through training batches, perform training steps, calculate the training loss *per batch*.\n",
    "3. Loop through testing batches, perform testing steps, calculate the test loss *per batch*\n",
    "4. Print out what's happening.\n",
    "5. Time it all (for fun)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7541c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set the seed and start the timer\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "# Set the number of epochs (we'll keep this small for faster training time)\n",
    "epochs = 3\n",
    "\n",
    "# Create training and test loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-----\")\n",
    "    ### Training\n",
    "    train_loss = 0\n",
    "    # Add a loop to loop through the training batches\n",
    "    for batch, (x, y) in enumerate(train_dataloader):\n",
    "        model_0.train()\n",
    "        # 1. Forward pass\n",
    "        y_pred = model_0(x)\n",
    "\n",
    "        # 2. Calculate the loss (per batch)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss  # accumulate training loss\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print out what's happening\n",
    "        if batch % 400 == 0:\n",
    "            print(\n",
    "                f\"Looked at {batch * len(x)}/{len(train_dataloader.dataset)} samples.\"\n",
    "            )\n",
    "\n",
    "        # Divide total train loss by length of train dataloader\n",
    "        train_loss /= len(train_dataloader)\n",
    "\n",
    "    ### Testing\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        for x_test, y_test in test_dataloader:\n",
    "            # 1. Forward pass\n",
    "            test_pred = model_0(x_test)\n",
    "            \n",
    "            # 2. Calculate the loss\n",
    "            test_loss += loss_fn(test_pred, y_test)\n",
    "            \n",
    "            # 3. Calculate accouracy\n",
    "            test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(1))\n",
    "            \n",
    "        # Calculate the test loss average per batch\n",
    "        test_loss /= len(test_dataloader)\n",
    "        \n",
    "        # Calculate the test acc averave per batch\n",
    "        test_acc /= len(test_dataloader)\n",
    "        \n",
    "    # Print out what's happening\n",
    "    print(f\"\\nTrain loss: {train_loss: .4f} | Test loss: {test_loss: .4f}, Test acc: {test_acc: .4f}\")\n",
    "    \n",
    "# Calculate training time\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu, end=train_time_end_on_cpu, device=str(next(model_0.parameters()).device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023d6c7e",
   "metadata": {},
   "source": [
    "#### 5. Setup device agnostic-code (for using a GPU if there is one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef73bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437b7726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device-agnostic code\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d0fd98",
   "metadata": {},
   "source": [
    "### 4. Make predictions and get Model 0 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074b0140",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "def eval_model(\n",
    "    model: torch.nn.Module,\n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    accuracy_fn,\n",
    "    device: torch.device = device\n",
    "):\n",
    "    \"\"\"Returns a dictionary containing the results of model predicting on the data_loader.\"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for x, y in tqdm(data_loader):\n",
    "            # Make our data device agnostic\n",
    "            x,y = x.to(device), y.to(device)\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = model(x)  # forward pass\n",
    "\n",
    "            # Accumulate the loss and acc values per batch\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "        # Scale loss and acc to find the average loss/acc per batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "\n",
    "    return {\n",
    "        \"model_name\": model.__class__.__name__,  # only works when model is created using a class\n",
    "        \"model_loss\": loss.item(),\n",
    "        \"model_acc\": acc,\n",
    "    }\n",
    "\n",
    "\n",
    "# Calculate model 0 results on test dataset\n",
    "model_0_results = eval_model(\n",
    "    model_0, data_loader=test_dataloader, loss_fn=loss_fn, accuracy_fn=accuracy_fn, device='cpu'\n",
    ")\n",
    "\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91a7eca",
   "metadata": {},
   "source": [
    "### 6. Model 1: Building a better model with non-linearity\n",
    "\n",
    "We learned about the power of non-linearity in notebook 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674021f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model with non-linear and linear layers\n",
    "class FashionMNISTModelV1(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(), # flatten inputs into single vector\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0328c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of model_1\n",
    "torch.manual_seed(42)\n",
    "model_1 = FashionMNISTModelV1(\n",
    "    input_shape=784,  # this is the output of the flatten layer our 28*28 images goes in\n",
    "    hidden_units=10,\n",
    "    output_shape=len(class_names),\n",
    ").to(\n",
    "    device\n",
    ") # send to the GPU if it's available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d061218",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model_1.parameters()).device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a290ce",
   "metadata": {},
   "source": [
    "#### 6.1 Setup loss, optimizer and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be205c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "loss_fn = nn.CrossEntropyLoss() # measures how wrong out model is\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(), lr=0.1) # tries to update the parameters to reduce the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa398fee",
   "metadata": {},
   "source": [
    "#### 6.2 Functionizing training and evaluation/testing loops\n",
    "\n",
    "Let's create a function for:\n",
    "* training loop - `train_step()`\n",
    "* testing loop - `test_step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b7cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_setp(\n",
    "    model: torch.nn.Module,\n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    accuracy_fn,\n",
    "    device: torch.device = device,\n",
    "):\n",
    "    \"\"\"Performs a training with model trying to learn on data_loader.\"\"\"\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    ### Training\n",
    "    train_loss = 0\n",
    "\n",
    "    # Put model into training mode\n",
    "    model.train()\n",
    "\n",
    "    # Add a loop to loop through the training batches\n",
    "    for batch, (x, y) in enumerate(data_loader):\n",
    "        # Put data on target device\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass (outputs the raw logits from the model)\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # 2. Calculate loss and accuracy (per batch)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss  # accumulate training loss\n",
    "        train_acc += accuracy_fn(\n",
    "            y_true=y, y_pred=y_pred.argmax(dim=1)\n",
    "        )  # go from logits -> prediction labels\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Divide total train loss and accuracy by length of train dataloader\n",
    "        train_loss /= len(data_loader)\n",
    "        train_acc /= len(data_loader)\n",
    "\n",
    "    # Print out what's happening\n",
    "    # if batch % 400 == 0:\n",
    "    # print(f\"Looked at {batch * len(x)}/{len(data_loader.dataset)} samples.\")\n",
    "\n",
    "    print(f\"Train loss: {train_loss: .5f} | Train acc: {train_acc: .2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a34e4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(\n",
    "    model: torch.nn.Module,\n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    accuracy_fn,\n",
    "    device: torch.device = device,\n",
    "):\n",
    "    \"\"\"Performs a testing loop step on model going over data_loader.\"\"\"\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    # Put the model in eval model\n",
    "    model.eval()\n",
    "\n",
    "    # Turn on inference model context manager\n",
    "    with torch.inference_mode():\n",
    "        for x, y in data_loader:\n",
    "            # send the data to the target device\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            test_pred = model(x)\n",
    "\n",
    "            # 2. Calculate the loss/acc\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(\n",
    "                y_true=y,\n",
    "                y_pred=test_pred.argmax(dim=1),  # go from logits -> prediction labels\n",
    "            )\n",
    "\n",
    "        # Adjust metrics and print out\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"Test loss: {test_loss: .5f} | Test acc: {test_acc: .2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923f627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "# Set epochs\n",
    "epochs = 3\n",
    "\n",
    "# Create an optimization and evaluation loop using train_step() and test_step()\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epochs: {epoch}\\n-------\")\n",
    "    train_setp(\n",
    "        model=model_1,\n",
    "        data_loader=train_dataloader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    test_step(\n",
    "        model=model_1,\n",
    "        data_loader=test_dataloader,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "train_time_end_on_gpu = timer()\n",
    "total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu, end=train_time_end_on_gpu, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765547f3",
   "metadata": {},
   "source": [
    "**Note:** Sometimes, depending on your data/hardware you might find that your model trains faster on CPU than GPU.\n",
    "\n",
    "Why is this?\n",
    "\n",
    "1. It could be that the overhead for copying data/model to and from the GPU outweights the compute benefits offered by the GPU.\n",
    "2. The hardware you're using has a better CPU in terms of compute capability than the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79b6995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train time on CPU, Train time on GPU\n",
    "total_train_time_model_0, total_train_time_model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c451975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model_1 results dictionary\n",
    "model_1_results = eval_model(\n",
    "    model=model_1, data_loader=test_dataloader, loss_fn=loss_fn, accuracy_fn=accuracy_fn, device=device\n",
    ")\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8124bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
